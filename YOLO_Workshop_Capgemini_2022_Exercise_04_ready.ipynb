{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bees4ever/ai-workshop-2022/blob/main/YOLO_Workshop_Capgemini_2022_Exercise_04_ready.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Detection Workshop\n",
        "*Capgemini Challenge*\n",
        "\n",
        "Catch the thief through image analysis and prove your analytical skill!\n",
        "\n",
        "Estimated Duration:"
      ],
      "metadata": {
        "id": "KavPAYN75oj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theft of a branded teddy bear\n",
        "\n",
        "A valuable teddy bear was stolen from the shopping center. Witnesses saw the thief with the teddy bear in his arms. Your task is to search the surveillance camera images in an automated way to hand over a picture of the person to the police.\n",
        "To do this, extract all the crops with a teddy bear. Find the thief by overlapping the bounding boxes of the teddy bear and the person.\n"
      ],
      "metadata": {
        "id": "hVThJ5dm81kM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The data are downloaded from kaggle and underly different lizenses, even unkown.\n",
        "\n",
        "- https://www.kaggle.com/datasets/odins0n/ucf-crime-dataset (CC0 lizense)\n",
        "- https://www.kaggle.com/datasets/fmena14/crowd-counting (unkown)\n",
        "\n"
      ],
      "metadata": {
        "id": "frfOgoCaFJ91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Load Dataset\n"
      ],
      "metadata": {
        "id": "7k4mwNNA9K6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/bees4ever/ai-workshop-2022/raw/main/surveillance_dataset/workshop_task_04_dataset.zip\n",
        "!unzip workshop_task_04_dataset"
      ],
      "metadata": {
        "id": "2m_B5zQtHuE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we learned from previous task, we"
      ],
      "metadata": {
        "id": "1yUSkBEXHF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO v5\n",
        "!git clone  'https://github.com/ultralytics/yolov5.git'\n",
        "!pip install -qr '/content/yolov5/requirements.txt'  # install dependencies"
      ],
      "metadata": {
        "id": "Fdfp1LFSHGJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' Run object detection\n",
        "# !python yolov5/detect.py --source /content/workshop_task_04_dataset  --save-crop"
      ],
      "metadata": {
        "id": "RGkOBiPYQqFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Model\n",
        "model = torch.hub.load('ultralytics/yolov3', 'yolov3')  # oder yolov3-spp, yolov3-tiny, custom# Inference f√ºr Bild erstellen\n",
        "\n"
      ],
      "metadata": {
        "id": "WXhEfBlT_xV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Load prepared Functions\n",
        "\n",
        "Run the following code snippet to load some prepared function which you should use for your calculation, later.\n"
      ],
      "metadata": {
        "id": "exefIutRXmic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_iou(bb1, bb2):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bb1 : dict\n",
        "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "        The (x1, y1) position is at the top left corner,\n",
        "        the (x2, y2) position is at the bottom right corner\n",
        "    bb2 : dict\n",
        "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
        "        The (x, y) position is at the top left corner,\n",
        "        the (x2, y2) position is at the bottom right corner\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        in [0, 1]\n",
        "    \"\"\"\n",
        "    assert bb1['x1'] < bb1['x2']\n",
        "    assert bb1['y1'] < bb1['y2']\n",
        "    assert bb2['x1'] < bb2['x2']\n",
        "    assert bb2['y1'] < bb2['y2']\n",
        "\n",
        "    # determine the coordinates of the intersection rectangle\n",
        "    x_left = max(bb1['x1'], bb2['x1'])\n",
        "    y_top = max(bb1['y1'], bb2['y1'])\n",
        "    x_right = min(bb1['x2'], bb2['x2'])\n",
        "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    # The intersection of two axis-aligned bounding boxes is always an\n",
        "    # axis-aligned bounding box\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    # compute the area of both AABBs\n",
        "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
        "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
        "    assert iou >= 0.0\n",
        "    assert iou <= 1.0\n",
        "    return iou\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "def torch2dict(box):\n",
        "  return {'x1': box[0].item(), 'x2': box[2].item(), 'y1': box[1].item(), 'y2': box[3].item()}\n",
        "\n",
        "def getLabel(x):\n",
        "  return \" \".join(x['label'].split(\" \")[0:-1])\n",
        "\n",
        "def checkOverlap(overlap, label1, label2):\n",
        "  return (getLabel(overlap[\"image1\"]) == label1 and getLabel(overlap[\"image2\"]) == label2) or (getLabel(overlap[\"image1\"]) == label2 and getLabel(overlap[\"image2\"]) == label1)\n",
        "\n",
        "def box2Height(box):\n",
        "  box_encoded = torch2dict(box)\n",
        "  return box_encoded['y2'] - box_encoded['y1']\n",
        "\n",
        "def boxSimilarHeight(box1, box2):\n",
        "  heights = [box2Height(box1), box2Height(box2)]\n",
        "  heights = np.sort(heights)\n",
        "  return heights[0] / heights[1] >= 0.60\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "DELVe4RBC1Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Your turn, detect a person with a big teddy close to it\n",
        "\n",
        "First, we provide some hints, then you also need to fill the prepared code snippet with your solutions.\n",
        "\n",
        "If you want to write a complete own function you are more then invited to do so.\n"
      ],
      "metadata": {
        "id": "8eK9pf18589W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hints for your solution:\n",
        "\n",
        "- use the function provided above, called `get_iou`\n",
        "- as shown below, use `itertools.combinations` to compare all objects\n",
        "- interesting objects regarding stolen teddy might be objects from almost same height, you can use the function `boxSimilarHeight`\n"
      ],
      "metadata": {
        "id": "DJz1g02BADPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#' TODO: fill all <> with the missing solution!\n",
        "\n",
        "import os\n",
        "from progressbar import progressbar\n",
        "import itertools\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for img in progressbar(os.listdir(\"workshop_task_04_dataset\")):\n",
        "  img_path = os.path.join(\"workshop_task_04_dataset\", img)\n",
        "  results = model(img_path)\n",
        "  crops = results.crop() \n",
        "  # xmin    ymin    xmax   ymax  confidence  class\n",
        "  # bounding_boxes contains all found bounding boxes of current image\n",
        "  bounding_boxes = results.xyxy[0]\n",
        "  overlap_crops = []\n",
        "  \n",
        "  \n",
        "  for (box1, crop1), (box2, crop2) in itertools.combinations(zip(bounding_boxes, crops), 2):\n",
        "    overlap = get_iou(torch2dict(box1), torch2dict(box2))\n",
        "    if overlap > 0 and overlap < 1:\n",
        "      overlap_crops.append({\"image1\": crop1, \"image2\": crop2, \"overlap\": overlap, \"box1\": box1, \"box2\": box2})\n",
        "  \n",
        "  #' TODO: \n",
        "  for <> in overlap_crops:\n",
        "      #' TODO, \n",
        "    if checkOverlap(overlap, <label1>, <label2>) and boxSimilarHeight(<>, <>):\n",
        "      cv2_imshow(overlap[\"image1\"][\"im\"])\n",
        "      cv2_imshow(overlap[\"image2\"][\"im\"])\n",
        "      \n",
        "      #' Hint: with getLabel(overlap[\"image1\"]) you can print the label name\n",
        "      #' TODO, what should be returned?\n",
        "      print(<>)\n",
        "      \n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "wMSwV1AWS46-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}