{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bees4ever/ai-workshop-2022/blob/main/YOLO_Workshop_Capgemini_2022_Exercise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5\n",
        "\n",
        "Yolo Training.\n",
        "\n",
        "\n",
        "The challenge of this task is to train and finetune an own Yolo Model. For this purpose a labeled dataset has been prepared."
      ],
      "metadata": {
        "id": "A1x08GPIHIey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Download the data\n",
        "\n",
        "Run the following command to download the data."
      ],
      "metadata": {
        "id": "xPcpftcdHVPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjpI8yvoMgT_"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/bees4ever/ai-workshop-2022/blob/main/yolo_sample/custom_yolo_masked_person_poc_all_v05.zip?raw=true -O custom_yolo_masked_person_poc_all_v05.zip\n",
        "!unzip custom_yolo_masked_person_poc_all_v05.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4e9h0HfVA30"
      },
      "source": [
        "## Step 2 Data Preprocessing\n",
        "\n",
        "The labeles are available in POX XML format. We need to convert it to a YOLO understandable format. Some steps are prepared, but you also need to do invest some time to complete the transformation.\n",
        "\n",
        "First, we do an extraction of data labels from .xml file to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qj5wjt0-fRbS"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os, sys, random\n",
        "import xml.etree.ElementTree as ET\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from shutil import copyfile\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, model_selection\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import patches\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_8R_DIIiQEY"
      },
      "outputs": [],
      "source": [
        "annotations = sorted(glob('/content/custom_yolo_masked_person_poc_all_v05/labels/*.xml'))\n",
        "# hint: parsedXML\n",
        "\n",
        "\n",
        "df = []\n",
        "cnt = 0\n",
        "for file in annotations:\n",
        "  prev_filename = file.split('/')[-1].split('.')[0] + '.jpeg'\n",
        "  filename = str(cnt) + '.jpg'\n",
        "  row = []\n",
        "  parsedXML = ET.parse(file)\n",
        "  img_width = int(float(parsedXML.getroot().find('size/width').text))\n",
        "  img_height = int(float(parsedXML.getroot().find('size/height').text))\n",
        "\n",
        "  for node in parsedXML.getroot().iter('object'):\n",
        "    blood_cells = node.find('name').text\n",
        "    xmin = int(float(node.find('bndbox/xmin').text))\n",
        "    xmax = int(float(node.find('bndbox/xmax').text))\n",
        "    ymin = int(float(node.find('bndbox/ymin').text))\n",
        "    ymax = int(float(node.find('bndbox/ymax').text))\n",
        "\n",
        "    row = [prev_filename, filename, blood_cells, xmin, xmax, ymin, ymax, img_width, img_height]\n",
        "    df.append(row)\n",
        "  cnt += 1\n",
        "\n",
        "data = pd.DataFrame(df, columns=['prev_filename', 'filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax', 'img_width', 'img_height'])\n",
        "\n",
        "data[['prev_filename','filename', 'cell_type', 'xmin', 'xmax', 'ymin', 'ymax','img_width', 'img_height']].to_csv('/content/custom_yolo_masked_person.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6cRsoE6VRAD"
      },
      "source": [
        "### Step 3: Process dataframe and generate the YOLO_V5 compatible labeles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onr1Vqm4x4qz"
      },
      "source": [
        "*Hint, the data frame has following structure:* \n",
        "\n",
        "- filename : contains the name of the image\n",
        "- cell_type: denotes the type of the cell\n",
        "- xmin: x-coordinate of the bottom left part of the image\n",
        "- xmax: x-coordinate of the top right part of the image\n",
        "- ymin: y-coordinate of the bottom left part of the image\n",
        "- ymax: y-coordinate of the top right part of the image\n",
        "- labels : Encoded cell-type **(Yolo - label input-1)**\n",
        "- width : width of that bbox\n",
        "- height : height of that bbox\n",
        "- x_center : bbox center (x-axis)\n",
        "-\ty_center : bbox center (y-axis)\n",
        "-\tx_center_norm\t: x_center normalized (0-1) **(Yolo - label input-2)**\n",
        "-\ty_center_norm : y_center normalized (0-1) **(Yolo - label input-3)**\n",
        "- width_norm : width normalized (0-1) **(Yolo - label input-4)**\n",
        "-\theight_norm : height normalized (0-1) **(Yolo - label input-5)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia0Ye75Zh_3a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/custom_yolo_masked_person.csv')\n",
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rybfBj3mwBV"
      },
      "outputs": [],
      "source": [
        "#img_width = 640\n",
        "#img_height = 480\n",
        "\n",
        "def width(df):\n",
        "  return int(df.xmax - df.xmin)\n",
        "def height(df):\n",
        "  return int(df.ymax - df.ymin)\n",
        "def x_center(df):\n",
        "  return int(df.xmin + (df.width/2))\n",
        "def y_center(df):\n",
        "  return int(df.ymin + (df.height/2))\n",
        "\n",
        "df = pd.read_csv('/content/custom_yolo_masked_person.csv')\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(df['cell_type'])\n",
        "print(le.classes_)\n",
        "labels = le.transform(df['cell_type'])\n",
        "df['labels'] = labels\n",
        "\n",
        "df['width'] = df.apply(width, axis=1)\n",
        "df['height'] = df.apply(height, axis=1)\n",
        "\n",
        "df['x_center'] = df.apply(x_center, axis=1)\n",
        "df['y_center'] = df.apply(y_center, axis=1)\n",
        "\n",
        "df['x_center_norm'] = df['x_center']/df.img_width\n",
        "df['width_norm'] = df['width']/df.img_width\n",
        "\n",
        "df['y_center_norm'] = df['y_center'] / df.img_height\n",
        "df['height_norm'] = df['height']/ df.img_height\n",
        "\n",
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk4xn6BJ4B6q"
      },
      "outputs": [],
      "source": [
        "#@title SAMPLE PLOT - shape (480, 640, 3)\n",
        "fig = plt.figure()\n",
        "import cv2\n",
        "#add axes to the image\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "# read and plot the image\n",
        "image = plt.imread('/content/custom_yolo_masked_person_poc_all_v05/images/ana-itonishvili-_meIjZYso8M-unsplash.jpeg')\n",
        "plt.imshow(image)\n",
        "\n",
        "# iterating over the image for different objects\n",
        "for _,row in df[df.prev_filename == \"ana-itonishvili-_meIjZYso8M-unsplash.jpeg\"].iterrows():\n",
        "    xmin = row.xmin\n",
        "    xmax = row.xmax\n",
        "    ymin = row.ymin\n",
        "    ymax = row.ymax\n",
        "    \n",
        "    width = xmax - xmin\n",
        "    height = ymax - ymin\n",
        "    print(row)\n",
        "    # assign different color to different classes of objects\n",
        "    if row.cell_type == 'Person':\n",
        "        edgecolor = 'r'\n",
        "        ax.annotate('Person', xy=(xmax-40,ymin+20))\n",
        "    elif row.cell_type == 'Masked':\n",
        "        edgecolor = 'b'\n",
        "        ax.annotate('Masked', xy=(xmax-40,ymin+20))\n",
        "\n",
        "        \n",
        "    # add bounding boxes to the image\n",
        "    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')\n",
        "    \n",
        "    ax.add_patch(rect)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLnE5tWOVaKM"
      },
      "source": [
        "# Splitting into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRrIQI7m8H5P"
      },
      "outputs": [],
      "source": [
        "df_train, df_valid = model_selection.train_test_split(df, test_size=0.1, random_state=13, shuffle=True)\n",
        "print(df_train.shape, df_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO6iT6rQ-2f3"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/custom_masked_person/')\n",
        "os.mkdir('/content/custom_masked_person/images/')\n",
        "os.mkdir('/content/custom_masked_person/images/train/')\n",
        "os.mkdir('/content/custom_masked_person/images/valid/')\n",
        "\n",
        "os.mkdir('/content/custom_masked_person/labels/')\n",
        "os.mkdir('/content/custom_masked_person/labels/train/')\n",
        "os.mkdir('/content/custom_masked_person/labels/valid/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IACNN0QxC4s"
      },
      "source": [
        "**STRUCTURE OF .txt FILE**\n",
        "\n",
        "- One row per object\n",
        "- Each row is class x_center y_center width height format.\n",
        "- Box coordinates must be in normalized xywh format (from 0 - 1). If your boxes  are in pixels, divide x_center and width by image width, and y_center and height by image height.\n",
        "- Class numbers are zero-indexed (start from 0).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo21M14uF25h"
      },
      "outputs": [],
      "source": [
        "def segregate_data(df, img_path, train_img_path, train_label_path):\n",
        "  filenames = []\n",
        "  for filename in df.filename:\n",
        "    filenames.append(filename)\n",
        "  filenames = set(filenames)\n",
        "  \n",
        "  for filename in filenames:\n",
        "    yolo_list = []\n",
        "\n",
        "    for _,row in df[df.filename == filename].iterrows():\n",
        "      yolo_list.append([row.labels, row.x_center_norm, row.y_center_norm, row.width_norm, row.height_norm])\n",
        "\n",
        "    yolo_list = np.array(yolo_list)\n",
        "    print(os.path.join(train_label_path,str(row.prev_filename.split('.')[0])+\".txt\"))\n",
        "    txt_filename = os.path.join(train_label_path,str(row.prev_filename.split('.')[0])+\".txt\")\n",
        "    # Save the .img & .txt files to the corresponding train and validation folders\n",
        "    np.savetxt(txt_filename, yolo_list, fmt=[\"%d\", \"%f\", \"%f\", \"%f\", \"%f\"])\n",
        "    shutil.copyfile(os.path.join(img_path,row.prev_filename), os.path.join(train_img_path,row.prev_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uy4rLGYSBd7"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "src_img_path = \"/content/custom_yolo_masked_person_poc_all_v05/images\"\n",
        "\n",
        "train_img_path = \"/content/custom_masked_person/images/train/\"\n",
        "train_label_path = \"/content/custom_masked_person/labels/train/\"\n",
        "\n",
        "\n",
        "valid_img_path = \"/content/custom_masked_person/images/valid\"\n",
        "valid_label_path = \"/content/custom_masked_person/labels/valid\"\n",
        "\n",
        "segregate_data(df_train, src_img_path, train_img_path, train_label_path)\n",
        "segregate_data(df_valid, src_img_path, valid_img_path, valid_label_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDv31-CdS_nt"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  shutil.rmtree('/content/bcc/images/train/.ipynb_checkpoints')\n",
        "except FileNotFoundError:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  shutil.rmtree('/content/bcc/images/valid/.ipynb_checkpoints')\n",
        "except FileNotFoundError:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  shutil.rmtree('/content/bcc/labels/train/.ipynb_checkpoints')\n",
        "except FileNotFoundError:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  shutil.rmtree('/content/bcc/labels/valid/.ipynb_checkpoints')\n",
        "except FileNotFoundError:\n",
        "  pass\n",
        "\n",
        "print(\"No. of Training images\", len(os.listdir(train_img_path)))\n",
        "print(\"No. of Training labels\", len(os.listdir(train_label_path)))\n",
        "\n",
        "print(\"No. of valid images\", len(os.listdir(valid_img_path)))\n",
        "print(\"No. of valid labels\", len(os.listdir(valid_label_path)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjHmEIfmWNms"
      },
      "source": [
        "# Step 4: Training session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05kiA297y2s3"
      },
      "outputs": [],
      "source": [
        "!mkdir -p '/content/drive/My Drive/Machine Learning Projects/YOLO/'\n",
        "!cp -r '/content/custom_masked_person' '/content/drive/My Drive/Machine Learning Projects/YOLO/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcA59GtHeCrd"
      },
      "source": [
        "Clone the yolo v5 repository.\n",
        "More can be found at here : [yolo](https://github.com/ultralytics/yolov5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnhcNiuTGAK7"
      },
      "outputs": [],
      "source": [
        "!git clone  'https://github.com/ultralytics/yolov5.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4i0BpZIbyTz"
      },
      "outputs": [],
      "source": [
        "!pip install -qr '/content/yolov5/requirements.txt'  # install dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUsMKPtGeUcv"
      },
      "source": [
        "# WE SHOULD CREATE A .yaml FILE AND THEN PLACE IT INSIDE THE yolov5 FOLDER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqymagYif3Us"
      },
      "source": [
        "#**Contents of YAML file**\n",
        "\n",
        "train: /content/custom_masked_person/images/train                    \n",
        "val: /content/custom_masked_person/images/valid\n",
        "\n",
        "nc: 2\n",
        "\n",
        "names: ['Masked', 'Person']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgIO3balXB-B"
      },
      "outputs": [],
      "source": [
        "!rm 'custom_yolo_masked_person.yaml'\n",
        "!echo -e 'train: /content/custom_masked_person/images/train\\nval: /content/custom_masked_person/images/valid\\n\\nnc: 2\\nnames: ['Masked', 'Person']' >> custom_yolo_masked_person.yaml\n",
        "!cat 'custom_yolo_masked_person.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31-z05sIcMcv"
      },
      "outputs": [],
      "source": [
        "shutil.copyfile('/content/custom_yolo_masked_person.yaml', '/content/yolov5/custom_yolo_masked_person.yaml')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gUcPKfsDlEQ"
      },
      "source": [
        "#**Also edit the number of classes (nc) in the ./models/*.yaml file**\n",
        "\n",
        "Choose the yolo model of your choice, here I chose yolov5s.yaml (yolo - small)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cXuPZjRhg3o"
      },
      "outputs": [],
      "source": [
        "!sed -i 's/nc: 80/nc: 2/g' ./yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r custom_masked_person.zip custom_masked_person"
      ],
      "metadata": {
        "id": "Giho3etWNrXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_4-F3I2gVIN"
      },
      "source": [
        "# Training command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "127Pw1oS1zzY"
      },
      "source": [
        "**Training Parameters**\n",
        "\n",
        "!python \n",
        "- <'location of train.py file'> \n",
        "- --img <'width of image'>\n",
        "- --batch <'batch size'>\n",
        "- --epochs <'no of epochs'>\n",
        "- --data <'location of the .yaml file'>\n",
        "- --cfg <'Which yolo configuration you want'>(yolov5s/yolov5m/yolov5l/yolov5x).yaml | (small, medium, large, xlarge)\n",
        "- --name <'Name of the best model after training'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztjc7_wS5z2J"
      },
      "source": [
        "**Metrics from Basic Training Process**\n",
        "\n",
        "**No.of classes, No.of images, No.of targets, Precision (P), Recall (R), mean Average Precision (map)**\n",
        "\n",
        "|Class | Images | Targets | P | R | mAP@.5 | mAP@.5:.95: |\n",
        "|---|---|---|---|---|---|---|\n",
        "| all   | 32    |     33 |   0.307 |       0.603  |      0.426 |      0.296|\n",
        "\n",
        "**Metrics from our best Training Process**\n",
        "\n",
        "**No.of classes, No.of images, No.of targets, Precision (P), Recall (R), mean Average Precision (map)**\n",
        "\n",
        "| Class | Images | Targets | P | R | mAP@.5 | mAP@.5:.95: |\n",
        "|---|---|---|---|---|---|---|\n",
        "| all   | 32    |     33 |   0.60775 |       0.69485  |      0.65497 |     0.49628|\n",
        "\n",
        "\n",
        "**Who is doing better??**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Tc61Qzd4lY"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#' basic training\n",
        "!python yolov5/train.py --img 640 --batch 1 --epochs 200 --data yolov5/custom_yolo_masked_person.yaml --cfg yolov5/models/yolov5s.yaml --name CriminalDetection"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download example Hyper Parameter YAML file. "
      ],
      "metadata": {
        "id": "f1c94NdW2_Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/bees4ever/ai-workshop-2022/main/hyp_evolve.yaml -O hyp_evolve.yaml"
      ],
      "metadata": {
        "id": "Nind8XKL28wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should download it and edit it with some code editor and upload it again, to run an own trainings session."
      ],
      "metadata": {
        "id": "eThtski13o2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#' training with none default hyperparameter, this is the solution we can provide\n",
        "#' TODO remove file and download the standart from yolo here, so students can play around with it\n",
        "\n",
        "%%time\n",
        "#' basic training\n",
        "!python yolov5/train.py --img 640 --batch 8 --epochs 100 --data yolov5/custom_yolo_masked_person.yaml --cfg yolov5/models/yolov5s.yaml --name CriminalDetectionHyp  --hyp  /content/hyp_evolve.yaml"
      ],
      "metadata": {
        "id": "4GSlsj1SJ7RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7upZcFvhWhN"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard (optional)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir yolov5/runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJYN1lb_uV-T"
      },
      "source": [
        "#**INFERENCE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtCUnoyr7h8y"
      },
      "source": [
        "**Inference Parameters**\n",
        "\n",
        "!python \n",
        "- <'location of detect.py file'> \n",
        "- --source <'location of image/ folder to predict'>\n",
        "- --weight <'location of the saved best weights'>\n",
        "- --output <'location of output files after prediction'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PoDLzE4xu_Bo"
      },
      "outputs": [],
      "source": [
        "!python yolov5/detect.py --source /content/custom_masked_person/images/valid/ --weights '/content/yolov5/runs/train/CriminalDetection/weights/best.pt'  --save-conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y5frHxMdm0Bd"
      },
      "outputs": [],
      "source": [
        "!unzip prepared.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tFR0-V7MML77"
      },
      "outputs": [],
      "source": [
        "!python yolov5/detect.py --source /content/prepared --weights '/content/yolov5/runs/train/CriminalDetection/weights/best.pt' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OS8SmXX_n6ZB"
      },
      "outputs": [],
      "source": [
        "!python yolov5/detect.py --source /content/custom_yolo_masked_person_poc_all_v05/images/ --weights '/content/yolov5/runs/train/CriminalDetection/weights/best.pt' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1UFERGRGwOEQ"
      },
      "outputs": [],
      "source": [
        "disp_images = glob('/content/yolov5/runs/detect/exp3/*')\n",
        "fig=plt.figure(figsize=(20*5, 28*5))\n",
        "columns = 4\n",
        "rows = 5\n",
        "for i in range(1, columns*rows +1):\n",
        "    img = np.random.choice(disp_images)\n",
        "    img = plt.imread(img)\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrXZ10ikvnDB"
      },
      "source": [
        "# SINGLE IMAGE PREDICTIONS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RuIiMYKdvRi1"
      },
      "outputs": [],
      "source": [
        "output = !python yolov5/detect.py --source /content/custom_yolo_masked_person_poc_all_v05/images/dave-spiess-QevEgXYHpzs-unsplash.jpeg --weights '/content/yolov5/runs/train/CriminalDetection/weights/best.pt'\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_eEHwUhvsct7"
      },
      "outputs": [],
      "source": [
        "#' export all predictions\n",
        "\n",
        "!zip -r detections.zip yolov5/runs/detect/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ZarG561ak5"
      },
      "source": [
        "# You need these files, if you wish to move the model to production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxI5iupx_jd1"
      },
      "source": [
        "## Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSAegF-48fHj"
      },
      "outputs": [],
      "source": [
        "shutil.copyfile('/content/yolov5/detect.py', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/detect.py')\n",
        "shutil.copyfile('/content/yolov5/requirements.txt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/requirements.txt')\n",
        "shutil.copyfile('/content/yolov5/runs/train/CriminalDetection/weights/best.pt', '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/best.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9PfbXGWTcYe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-aarpL_lB1"
      },
      "source": [
        "## Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1Gup2m3vv_M"
      },
      "outputs": [],
      "source": [
        "!cp -r '/content/yolov5/models' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n",
        "!cp -r '/content/yolov5/utils' '/content/drive/My Drive/Machine Learning Projects/YOLO/SOURCE/'\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}