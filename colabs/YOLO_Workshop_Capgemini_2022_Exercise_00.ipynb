{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bees4ever/ai-workshop-2022/blob/main/YOLO_Workshop_Capgemini_2022_Exercise_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crime Detection Workshop\n",
        "*Capgemini Challenge*\n",
        "\n",
        "Catch the thief through image analysis and prove your analytical skill!\n",
        "\n",
        "Estimated Duration: 10 min\n",
        "\n",
        "Challange Points: 0 "
      ],
      "metadata": {
        "id": "KavPAYN75oj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 0: Click & Learn\n",
        "In the following notebook we provide several excersices to detect a suspicious person of images of a suveillance camera.\n",
        "\n",
        "This Exercise is about to get ready with YOLO. Follow the prepared instructions to import the yolo framework and also some sample data set to do a first object detections.\n",
        "\n",
        "Also, this notebook helps you to solve all other task. Try to understand all the different data processing and model forecasting steps, which you can use later.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hVThJ5dm81kM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The data are downloaded from kaggle and underly different lizenses, even unkown.\n",
        "\n",
        "- https://www.kaggle.com/datasets/odins0n/ucf-crime-dataset (CC0 lizense)\n",
        "- https://www.kaggle.com/datasets/fmena14/crowd-counting (unkown)\n",
        "\n"
      ],
      "metadata": {
        "id": "frfOgoCaFJ91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download YOLO\n",
        "Download the YOLO framework using the prepared dataset."
      ],
      "metadata": {
        "id": "7k4mwNNA9K6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/bees4ever/ai-workshop-2022/main/yolo_sample/requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "%matplotlib inline\n",
        "!pip install PIL"
      ],
      "metadata": {
        "id": "uaUGVCvS5uQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Sample Dataset\n",
        "\n",
        "Download some sample Image"
      ],
      "metadata": {
        "id": "uA58I0ihsXPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/bees4ever/ai-workshop-2022/raw/main/yolo_sample/seq_000018.jpg"
      ],
      "metadata": {
        "id": "x-pTkk_W2h4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get ready with YOLO\n",
        "\n",
        "Your task is to read the `README` of `https://github.com/ultralytics/yolov5` and get ready with YOLO:\n",
        "\n",
        "- find a matching YOLO model on Torch\n",
        "- analyse the downloaded data from previous step\n",
        "- which kind of data you can retreive from prediction\n",
        "- show some bounding boxes of detected objects"
      ],
      "metadata": {
        "id": "818qMsri-v9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are different possibilities to work with the YOLO model. \n",
        "# In this example we load the model from torch hub\n",
        "import torch\n",
        "# The variable `model` contains the yolov3 model.\n",
        "# This means, we can use `model` and insert a path to an image. \n",
        "# The return value contains the complete YOLO forecast\n",
        "model = torch.hub.load('ultralytics/yolov3', 'yolov3')\n",
        "\n"
      ],
      "metadata": {
        "id": "liBSU-GL_FTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' Let's have an example:\n",
        "#' We loaded the file 'seq_000018.jpg', it is availbe here on colab\n",
        "img = 'seq_000018.jpg'\n",
        "# Passing the img path to `model`, returns an results object\n",
        "results = model(img)\n",
        "\n",
        "# Let's spent some time to analyse `results`.\n",
        "\n"
      ],
      "metadata": {
        "id": "WXhEfBlT_xV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We see, results is an object of class models.common.Detections. Searching\n",
        "# for pytorch objects could help here\n",
        "print(results)\n",
        "print(type(results))"
      ],
      "metadata": {
        "id": "meCiwHxN5g9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will just play a bit around and investigate the possibilities\n",
        "# with results.pred, we get the prediction made from YOLO. The prediction \n",
        "# is done for every sequence provided, which in this case is only one\n",
        "# sequence\n",
        "results.pred\n"
      ],
      "metadata": {
        "id": "ztr-7aj85ig1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With `results` we can save all detected objects to a folder, this can be done\n",
        "# using:\n",
        "\n",
        "crops = results.crop(save=True)\n",
        "\n",
        "# In runs/detect/exp/crops you see all detected objects listed.\n",
        "\n",
        "# Using results.crop(save=False) the output is not saved to disk,\n",
        "# BUT in both cases in variable `crops` we have all found objects gathered \n",
        "# in one array, let's see:\n",
        "\n",
        "print(crops[0])"
      ],
      "metadata": {
        "id": "121Zg8Pg704w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' mapping the crops to the label we get a simple overview of available items\n",
        "# of this specific image\n",
        "list(map(lambda x: x['label'], crops))"
      ],
      "metadata": {
        "id": "IAnWPyUt8gCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' A similiar result can be archived using \n",
        "results.pandas().xywh[0].name"
      ],
      "metadata": {
        "id": "uLchzqBb9RQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' Here we get the clear name as a pandas Dataframe, which can be re used for \n",
        "# further calculations like object counting:\n",
        "amount_handbags = sum(\"handbag\" == results.pandas().xywh[0].name)\n",
        "print(f\"We found {amount_handbags} handbags\")"
      ],
      "metadata": {
        "id": "9jWEupcp9hAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# by the way, pandas Dataframes are helpfull to glue data together.\n",
        "# Let's say we want to collect the amount of handbags to the image number. \n",
        "from pandas import DataFrame\n",
        "# Create the Dataframe based on a `dict`\n",
        "df = DataFrame({'handbags': [0, 5, 2, 12, 3, 4], 'image': ['seq1', 'seq2', 'seq3', 'seq4', 'seq5', 'seq6']})\n",
        "\n",
        "# Then you can plot it, using:\n",
        "%matplotlib inline\n",
        "df.plot('image', 'handbags')\n"
      ],
      "metadata": {
        "id": "vSdK1KhZ91UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' Or you can create a histogram of available objects\n",
        "df = results.pandas().xywh[0].name\n",
        "df.hist()"
      ],
      "metadata": {
        "id": "mmBRhnHF_JXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results.pandas().xywh[0] to see the full inside of the prediction in DataFrame format\n",
        "results.pandas().xywh[0]"
      ],
      "metadata": {
        "id": "anr0jUs4EpDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the extracted crops"
      ],
      "metadata": {
        "id": "rGiWQGhT_53r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some steps before, we saw how to extract the crops.\n",
        "# There are different possibilities to work with the extracted objects.\n",
        "# For this reason it is usefull to take some time and think about\n",
        "# how this crops can be easily loaded into python.\n",
        "\n",
        "# Use the os library\n",
        "import os\n",
        "\n",
        "# For nice progressbars it is always cool to have it enabled\n",
        "import progressbar as pb\n",
        "import matplotlib\n",
        "\n",
        "# Load image processing tool of python\n",
        "import cv2\n",
        "\n",
        "# define the main dir\n",
        "main_dir = 'runs/detect/exp/crops/handbag'\n",
        "\n",
        "\n",
        "\n",
        "# We want to save all width and heights of the handbags in a dataframe\n",
        "df = {'width': [], 'height': [], 'imgname': []}\n",
        "for img in pb.progressbar(os.listdir(main_dir)):\n",
        "    img_path = os.path.join(main_dir, img) \n",
        "    shape = cv2.imread(img_path).shape\n",
        "    # shape is `shape == (480, 640, 3)` the height, width and dimension of the image\n",
        "    df['height'].append(shape[0])\n",
        "    df['width'].append(shape[1])\n",
        "    df['imgname'].append(img_path)\n",
        "    \n",
        "    \n",
        "df = DataFrame(df)\n",
        "df\n"
      ],
      "metadata": {
        "id": "DNtwmNno_U4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' It also can help to create a histogram of the image:\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "from pandas import DataFrame\n",
        "\n",
        "color = ('b','g','r')\n",
        "img_parsed = cv2.imread('seq_000018.jpg', -1)\n",
        "for channel,col in enumerate(color):\n",
        "    histr = cv2.calcHist([img_parsed], [channel], None, [256], [0,256])\n",
        "    plt.plot(histr, color = col)\n",
        "    plt.xlim([0, 256])\n",
        "plt.title('Histogram for color scale picture of seq_000018.jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AZvt4aJ4DfbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#' Let create a function which creates the analysis of this three channels\n",
        "\n",
        "\"\"\"\n",
        ":param: img_path the path to the image source\n",
        ":return: the color deviation of all three channels red, green, blue\n",
        "\"\"\"\n",
        "def img_hist(img_path):\n",
        "  color = ('b','g','r')\n",
        "  res = dict()\n",
        "  img_parsed = cv2.imread('seq_000018.jpg', -1)\n",
        "  for channel,col in enumerate(color):\n",
        "    histr = cv2.calcHist([img_parsed], [channel], None, [256], [0,256])\n",
        "    res[col] = histr.reshape(256)\n",
        "  \n",
        "  return res\n",
        "\n",
        "df = img_hist('seq_000018.jpg')\n",
        "print(df.keys())\n",
        "DataFrame(df)\n"
      ],
      "metadata": {
        "id": "mMWXrZSMFCtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The color deviation of the channel can give a usefull insight of a image frame\n",
        "# If the color channels are the same, then the image could be the same"
      ],
      "metadata": {
        "id": "9QcNPByVGMqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Work with a different YOLO model\n",
        "\n",
        "Now it is your turn - load different models from pythorch and re-run the above lines\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PclkLdNauRwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your turn here"
      ],
      "metadata": {
        "id": "QuBZh1x7aKnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Work with the YOLO Tools\n",
        "\n",
        "The YOLO Github repo contains different tools / scripts which helps to predict different image sources, also videos and made it possible to fine tune the model."
      ],
      "metadata": {
        "id": "wnQHObyasJS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we download the repo. Then we go through the detection and training toolset."
      ],
      "metadata": {
        "id": "243mJpH3Zm_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "RJkFfLfHGilW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the prediction tools from YOLO\n",
        "!python yolov5/detect.py --source /content/seq_000018.jpg  --save-crop\n"
      ],
      "metadata": {
        "id": "9V92ce0OaYdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}